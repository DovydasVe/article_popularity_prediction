{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81dbcd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import visualise_gridsearch, fetch_top_predictions, make_top_3\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline as SkPipeline\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.combine import SMOTETomek\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import KFold, TimeSeriesSplit, GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE, KMeansSMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82991883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution:\n",
      "shares\n",
      "0    35615\n",
      "1     4029\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/OnlineNewsPopularity.csv')\n",
    "df = df.rename(columns=lambda x: x.strip())\n",
    "y_raw = df['shares']\n",
    "\n",
    "POPULARITY_SPLIT = 0.9\n",
    "\n",
    "high_thresh = y_raw.quantile(POPULARITY_SPLIT)\n",
    "y_class = (y_raw >= high_thresh).astype(int)\n",
    "\n",
    "print(\"Class distribution:\")\n",
    "print(y_class.value_counts())\n",
    "\n",
    "df_sorted = df.copy().sort_values('timedelta', ascending=False)\n",
    "\n",
    "TRAIN_SPLIT = 0.85\n",
    "train_size = int(len(df_sorted) * TRAIN_SPLIT)\n",
    "\n",
    "train_df = df_sorted.iloc[:train_size]\n",
    "test_df = df_sorted.iloc[train_size:]\n",
    "\n",
    "X_train = train_df.drop(columns=['url', 'timedelta', 'shares'])\n",
    "y_train_class = (train_df['shares'] >= high_thresh).astype(int)\n",
    "y_train_reg_log = np.log1p(train_df['shares'])\n",
    "\n",
    "X_test_full = test_df.drop(columns=['url', 'timedelta', 'shares'])\n",
    "y_test_full_class = (test_df['shares'] >= high_thresh).astype(int)\n",
    "y_test_full_reg_log = np.log1p(test_df['shares'])\n",
    "\n",
    "test_splits = np.array_split(test_df, 100)\n",
    "\n",
    "X_test_sets = []\n",
    "y_test_sets_class = []\n",
    "y_test_sets_reg_log = []\n",
    "\n",
    "for ts in test_splits:\n",
    "    X_test_sets.append(ts.drop(columns=['url', 'timedelta', 'shares']))\n",
    "    y_test_sets_class.append((ts['shares'] >= high_thresh).astype(int))\n",
    "    y_test_sets_reg_log.append(np.log1p(ts['shares']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a97e25",
   "metadata": {},
   "source": [
    "**BASELINE CATBOOST-CLASSIFIER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4124346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x20a92d3aad0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 1. TRAIN BASELINE CATBOOST CLASSIFIER\n",
    "# ============================================================\n",
    "\n",
    "model = CatBoostClassifier(\n",
    "    iterations=300,\n",
    "    depth=6,\n",
    "    learning_rate=0.1,\n",
    "    loss_function=\"Logloss\",\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "853938a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CLASSIFICATION REPORT (FULL TEST SET) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.920     0.998     0.957      5466\n",
      "           1      0.250     0.008     0.016       481\n",
      "\n",
      "    accuracy                          0.918      5947\n",
      "   macro avg      0.585     0.503     0.487      5947\n",
      "weighted avg      0.865     0.918     0.881      5947\n",
      "\n",
      "\n",
      "=== CONFUSION MATRIX ===\n",
      "[[5454   12]\n",
      " [ 477    4]]\n",
      "\n",
      "Test ROC-AUC: 0.733\n",
      "\n",
      "=== DAILY TOP‑3 HIT RESULTS ===\n",
      "Day 1: 0 / 3 correct\n",
      "Day 2: 1 / 3 correct\n",
      "Day 3: 1 / 3 correct\n",
      "Day 4: 0 / 3 correct\n",
      "Day 5: 0 / 3 correct\n",
      "Day 6: 2 / 3 correct\n",
      "Day 7: 0 / 3 correct\n",
      "Day 8: 0 / 3 correct\n",
      "Day 9: 0 / 3 correct\n",
      "Day 10: 0 / 3 correct\n",
      "Day 11: 1 / 3 correct\n",
      "Day 12: 0 / 3 correct\n",
      "Day 13: 0 / 3 correct\n",
      "Day 14: 1 / 3 correct\n",
      "Day 15: 0 / 3 correct\n",
      "Day 16: 0 / 3 correct\n",
      "Day 17: 0 / 3 correct\n",
      "Day 18: 0 / 3 correct\n",
      "Day 19: 0 / 3 correct\n",
      "Day 20: 1 / 3 correct\n",
      "Day 21: 1 / 3 correct\n",
      "Day 22: 0 / 3 correct\n",
      "Day 23: 0 / 3 correct\n",
      "Day 24: 1 / 3 correct\n",
      "Day 25: 0 / 3 correct\n",
      "Day 26: 0 / 3 correct\n",
      "Day 27: 0 / 3 correct\n",
      "Day 28: 0 / 3 correct\n",
      "Day 29: 0 / 3 correct\n",
      "Day 30: 1 / 3 correct\n",
      "Day 31: 1 / 3 correct\n",
      "Day 32: 0 / 3 correct\n",
      "Day 33: 1 / 3 correct\n",
      "Day 34: 0 / 3 correct\n",
      "Day 35: 0 / 3 correct\n",
      "Day 36: 0 / 3 correct\n",
      "Day 37: 0 / 3 correct\n",
      "Day 38: 1 / 3 correct\n",
      "Day 39: 0 / 3 correct\n",
      "Day 40: 0 / 3 correct\n",
      "Day 41: 0 / 3 correct\n",
      "Day 42: 1 / 3 correct\n",
      "Day 43: 1 / 3 correct\n",
      "Day 44: 1 / 3 correct\n",
      "Day 45: 1 / 3 correct\n",
      "Day 46: 1 / 3 correct\n",
      "Day 47: 0 / 3 correct\n",
      "Day 48: 0 / 3 correct\n",
      "Day 49: 0 / 3 correct\n",
      "Day 50: 0 / 3 correct\n",
      "Day 51: 0 / 3 correct\n",
      "Day 52: 0 / 3 correct\n",
      "Day 53: 1 / 3 correct\n",
      "Day 54: 1 / 3 correct\n",
      "Day 55: 2 / 3 correct\n",
      "Day 56: 0 / 3 correct\n",
      "Day 57: 0 / 3 correct\n",
      "Day 58: 0 / 3 correct\n",
      "Day 59: 0 / 3 correct\n",
      "Day 60: 1 / 3 correct\n",
      "Day 61: 1 / 3 correct\n",
      "Day 62: 1 / 3 correct\n",
      "Day 63: 1 / 3 correct\n",
      "Day 64: 0 / 3 correct\n",
      "Day 65: 0 / 3 correct\n",
      "Day 66: 1 / 3 correct\n",
      "Day 67: 0 / 3 correct\n",
      "Day 68: 3 / 3 correct\n",
      "Day 69: 0 / 3 correct\n",
      "Day 70: 0 / 3 correct\n",
      "Day 71: 0 / 3 correct\n",
      "Day 72: 1 / 3 correct\n",
      "Day 73: 0 / 3 correct\n",
      "Day 74: 1 / 3 correct\n",
      "Day 75: 0 / 3 correct\n",
      "Day 76: 2 / 3 correct\n",
      "Day 77: 0 / 3 correct\n",
      "Day 78: 0 / 3 correct\n",
      "Day 79: 1 / 3 correct\n",
      "Day 80: 1 / 3 correct\n",
      "Day 81: 1 / 3 correct\n",
      "Day 82: 0 / 3 correct\n",
      "Day 83: 2 / 3 correct\n",
      "Day 84: 1 / 3 correct\n",
      "Day 85: 1 / 3 correct\n",
      "Day 86: 0 / 3 correct\n",
      "Day 87: 1 / 3 correct\n",
      "Day 88: 2 / 3 correct\n",
      "Day 89: 0 / 3 correct\n",
      "Day 90: 0 / 3 correct\n",
      "Day 91: 1 / 3 correct\n",
      "Day 92: 0 / 3 correct\n",
      "Day 93: 0 / 3 correct\n",
      "Day 94: 0 / 3 correct\n",
      "Day 95: 0 / 3 correct\n",
      "Day 96: 0 / 3 correct\n",
      "Day 97: 0 / 3 correct\n",
      "Day 98: 1 / 3 correct\n",
      "Day 99: 1 / 3 correct\n",
      "Day 100: 0 / 3 correct\n",
      "\n",
      "Average Top‑3 Hit Rate Across 100 Days: 0.4700\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 2. EVALUATION ON FULL TEST SET\n",
    "# ============================================================\n",
    "\n",
    "y_pred = model.predict(X_test_full)\n",
    "y_proba = model.predict_proba(X_test_full)[:, 1]\n",
    "\n",
    "print(\"\\n=== CLASSIFICATION REPORT (FULL TEST SET) ===\")\n",
    "print(classification_report(y_test_full_class, y_pred, digits=3))\n",
    "\n",
    "print(\"\\n=== CONFUSION MATRIX ===\")\n",
    "print(confusion_matrix(y_test_full_class, y_pred))\n",
    "\n",
    "auc = roc_auc_score(y_test_full_class, y_proba)\n",
    "print(f\"\\nTest ROC-AUC: {auc:.3f}\")\n",
    "\n",
    "# ============================================================\n",
    "# 3. DAILY TOP‑3 HIT EVALUATION (RANKING METRIC)\n",
    "# ============================================================\n",
    "\n",
    "daily_hits = []\n",
    "\n",
    "for X_day, y_day_class in zip(X_test_sets, y_test_sets_class):\n",
    "\n",
    "    # Skip empty days\n",
    "    if len(X_day) == 0:\n",
    "        daily_hits.append(0)\n",
    "        continue\n",
    "\n",
    "    # 1. Predict probabilities\n",
    "    y_proba_day = model.predict_proba(X_day)[:, 1]\n",
    "\n",
    "    # Ranking dataframe\n",
    "    day_df = pd.DataFrame({\n",
    "        \"proba\": y_proba_day,\n",
    "        \"true_popular\": y_day_class.values\n",
    "    })\n",
    "\n",
    "    # 2. Top‑3 predicted\n",
    "    top3_pred = day_df.sort_values(\"proba\", ascending=False).head(3)\n",
    "\n",
    "    # 3. Top‑3 true\n",
    "    top3_true = day_df.sort_values(\"true_popular\", ascending=False).head(3)\n",
    "\n",
    "    pred_idx = set(top3_pred.index)\n",
    "    true_idx = set(top3_true.index)\n",
    "\n",
    "    # 4. Count hits\n",
    "    hits = len(pred_idx & true_idx)\n",
    "    daily_hits.append(hits)\n",
    "\n",
    "# 5. Summary\n",
    "average_hits = np.mean(daily_hits)\n",
    "\n",
    "print(\"\\n=== DAILY TOP‑3 HIT RESULTS ===\")\n",
    "for day, hits in enumerate(daily_hits, start=1):\n",
    "    print(f\"Day {day}: {hits} / 3 correct\")\n",
    "\n",
    "print(f\"\\nAverage Top‑3 Hit Rate Across 100 Days: {average_hits:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364c3bbe",
   "metadata": {},
   "source": [
    "**SMOTE + UNDERSAMPLING + BASELINE CATBOOST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7340ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CLASSIFICATION REPORT (FULL TEST SET) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.922     0.988     0.954      5466\n",
      "           1      0.284     0.056     0.094       481\n",
      "\n",
      "    accuracy                          0.912      5947\n",
      "   macro avg      0.603     0.522     0.524      5947\n",
      "weighted avg      0.871     0.912     0.884      5947\n",
      "\n",
      "\n",
      "=== CONFUSION MATRIX ===\n",
      "[[5398   68]\n",
      " [ 454   27]]\n",
      "\n",
      "Test ROC-AUC: 0.733\n",
      "\n",
      "=== DAILY TOP‑3 HIT RESULTS ===\n",
      "Day 1: 0 / 3 correct\n",
      "Day 2: 1 / 3 correct\n",
      "Day 3: 1 / 3 correct\n",
      "Day 4: 0 / 3 correct\n",
      "Day 5: 0 / 3 correct\n",
      "Day 6: 1 / 3 correct\n",
      "Day 7: 0 / 3 correct\n",
      "Day 8: 0 / 3 correct\n",
      "Day 9: 0 / 3 correct\n",
      "Day 10: 0 / 3 correct\n",
      "Day 11: 0 / 3 correct\n",
      "Day 12: 0 / 3 correct\n",
      "Day 13: 0 / 3 correct\n",
      "Day 14: 0 / 3 correct\n",
      "Day 15: 1 / 3 correct\n",
      "Day 16: 0 / 3 correct\n",
      "Day 17: 0 / 3 correct\n",
      "Day 18: 0 / 3 correct\n",
      "Day 19: 1 / 3 correct\n",
      "Day 20: 1 / 3 correct\n",
      "Day 21: 0 / 3 correct\n",
      "Day 22: 0 / 3 correct\n",
      "Day 23: 0 / 3 correct\n",
      "Day 24: 1 / 3 correct\n",
      "Day 25: 1 / 3 correct\n",
      "Day 26: 1 / 3 correct\n",
      "Day 27: 0 / 3 correct\n",
      "Day 28: 1 / 3 correct\n",
      "Day 29: 0 / 3 correct\n",
      "Day 30: 1 / 3 correct\n",
      "Day 31: 1 / 3 correct\n",
      "Day 32: 1 / 3 correct\n",
      "Day 33: 1 / 3 correct\n",
      "Day 34: 0 / 3 correct\n",
      "Day 35: 0 / 3 correct\n",
      "Day 36: 0 / 3 correct\n",
      "Day 37: 0 / 3 correct\n",
      "Day 38: 1 / 3 correct\n",
      "Day 39: 0 / 3 correct\n",
      "Day 40: 1 / 3 correct\n",
      "Day 41: 0 / 3 correct\n",
      "Day 42: 0 / 3 correct\n",
      "Day 43: 0 / 3 correct\n",
      "Day 44: 1 / 3 correct\n",
      "Day 45: 1 / 3 correct\n",
      "Day 46: 0 / 3 correct\n",
      "Day 47: 0 / 3 correct\n",
      "Day 48: 0 / 3 correct\n",
      "Day 49: 0 / 3 correct\n",
      "Day 50: 0 / 3 correct\n",
      "Day 51: 0 / 3 correct\n",
      "Day 52: 0 / 3 correct\n",
      "Day 53: 0 / 3 correct\n",
      "Day 54: 1 / 3 correct\n",
      "Day 55: 2 / 3 correct\n",
      "Day 56: 0 / 3 correct\n",
      "Day 57: 0 / 3 correct\n",
      "Day 58: 0 / 3 correct\n",
      "Day 59: 0 / 3 correct\n",
      "Day 60: 0 / 3 correct\n",
      "Day 61: 2 / 3 correct\n",
      "Day 62: 1 / 3 correct\n",
      "Day 63: 2 / 3 correct\n",
      "Day 64: 1 / 3 correct\n",
      "Day 65: 1 / 3 correct\n",
      "Day 66: 1 / 3 correct\n",
      "Day 67: 1 / 3 correct\n",
      "Day 68: 3 / 3 correct\n",
      "Day 69: 0 / 3 correct\n",
      "Day 70: 1 / 3 correct\n",
      "Day 71: 0 / 3 correct\n",
      "Day 72: 1 / 3 correct\n",
      "Day 73: 2 / 3 correct\n",
      "Day 74: 1 / 3 correct\n",
      "Day 75: 0 / 3 correct\n",
      "Day 76: 1 / 3 correct\n",
      "Day 77: 0 / 3 correct\n",
      "Day 78: 0 / 3 correct\n",
      "Day 79: 0 / 3 correct\n",
      "Day 80: 0 / 3 correct\n",
      "Day 81: 1 / 3 correct\n",
      "Day 82: 1 / 3 correct\n",
      "Day 83: 2 / 3 correct\n",
      "Day 84: 0 / 3 correct\n",
      "Day 85: 1 / 3 correct\n",
      "Day 86: 1 / 3 correct\n",
      "Day 87: 2 / 3 correct\n",
      "Day 88: 1 / 3 correct\n",
      "Day 89: 0 / 3 correct\n",
      "Day 90: 0 / 3 correct\n",
      "Day 91: 1 / 3 correct\n",
      "Day 92: 0 / 3 correct\n",
      "Day 93: 0 / 3 correct\n",
      "Day 94: 0 / 3 correct\n",
      "Day 95: 1 / 3 correct\n",
      "Day 96: 0 / 3 correct\n",
      "Day 97: 0 / 3 correct\n",
      "Day 98: 0 / 3 correct\n",
      "Day 99: 0 / 3 correct\n",
      "Day 100: 0 / 3 correct\n",
      "\n",
      "Average Top‑3 Hit Rate Across 100 Days: 0.5000\n"
     ]
    }
   ],
   "source": [
    "oversample = SMOTE(\n",
    "    sampling_strategy=0.5,\n",
    "    random_state=42\n",
    "    )\n",
    "\n",
    "undersample = RandomUnderSampler(\n",
    "    sampling_strategy=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "cat_model = CatBoostClassifier(\n",
    "    iterations=500,\n",
    "    depth=6,\n",
    "    learning_rate=0.05,\n",
    "    loss_function='Logloss',\n",
    "    eval_metric='AUC',\n",
    "    verbose=False,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "pipeline = ImbPipeline(steps=[\n",
    "    ('smote', oversample),\n",
    "    ('under', undersample),\n",
    "    ('catboost', cat_model)\n",
    "])\n",
    "\n",
    "# ============================================================\n",
    "# 6. TRAIN MODEL (resampling only applied to training data)\n",
    "# ============================================================\n",
    "\n",
    "pipeline.fit(X_train, y_train_class)\n",
    "\n",
    "# ============================================================\n",
    "# 7. EVALUATE ON FULL TEST SET\n",
    "# ============================================================\n",
    "\n",
    "y_pred = pipeline.predict(X_test_full)\n",
    "y_proba = pipeline.predict_proba(X_test_full)[:, 1]\n",
    "\n",
    "print(\"\\n=== CLASSIFICATION REPORT (FULL TEST SET) ===\")\n",
    "print(classification_report(y_test_full_class, y_pred, digits=3))\n",
    "\n",
    "print(\"\\n=== CONFUSION MATRIX ===\")\n",
    "print(confusion_matrix(y_test_full_class, y_pred))\n",
    "\n",
    "auc = roc_auc_score(y_test_full_class, y_proba)\n",
    "print(f\"\\nTest ROC-AUC: {auc:.3f}\")\n",
    "\n",
    "# ============================================================\n",
    "# 8. DAILY TOP‑3 HIT EVALUATION (YOUR METHOD)\n",
    "# ============================================================\n",
    "\n",
    "daily_hits = []\n",
    "\n",
    "for X_day, y_day_class in zip(X_test_sets, y_test_sets_class):\n",
    "\n",
    "    if len(X_day) == 0:\n",
    "        daily_hits.append(0)\n",
    "        continue\n",
    "\n",
    "    # 1. Predict probabilities\n",
    "    y_proba_day = pipeline.predict_proba(X_day)[:, 1]\n",
    "\n",
    "    # Build ranking dataframe\n",
    "    day_df = pd.DataFrame({\n",
    "        \"proba\": y_proba_day,\n",
    "        \"true_popular\": y_day_class.values\n",
    "    })\n",
    "\n",
    "    # 2. Top‑3 predicted\n",
    "    top3_pred = day_df.sort_values(\"proba\", ascending=False).head(3)\n",
    "\n",
    "    # 3. Top‑3 true\n",
    "    top3_true = day_df.sort_values(\"true_popular\", ascending=False).head(3)\n",
    "\n",
    "    pred_idx = set(top3_pred.index)\n",
    "    true_idx = set(top3_true.index)\n",
    "\n",
    "    # 4. Count hits\n",
    "    hits = len(pred_idx & true_idx)\n",
    "    daily_hits.append(hits)\n",
    "\n",
    "# 5. Summary\n",
    "average_hits = np.mean(daily_hits)\n",
    "\n",
    "print(\"\\n=== DAILY TOP‑3 HIT RESULTS ===\")\n",
    "for day, hits in enumerate(daily_hits, start=1):\n",
    "    print(f\"Day {day}: {hits} / 3 correct\")\n",
    "\n",
    "print(f\"\\nAverage Top‑3 Hit Rate Across 100 Days: {average_hits:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd937c3",
   "metadata": {},
   "source": [
    "**BASELINE CATBOOST REGRESSOR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa45e9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CLASSIFICATION REPORT (REGRESSION MODEL) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.919     1.000     0.958      5466\n",
      "           1      0.000     0.000     0.000       481\n",
      "\n",
      "    accuracy                          0.919      5947\n",
      "   macro avg      0.460     0.500     0.479      5947\n",
      "weighted avg      0.845     0.919     0.880      5947\n",
      "\n",
      "\n",
      "=== CONFUSION MATRIX ===\n",
      "[[5464    2]\n",
      " [ 481    0]]\n",
      "\n",
      "Test ROC-AUC (regression-based): 0.728\n",
      "\n",
      "=== DAILY TOP‑3 HIT RESULTS (REGRESSION MODEL) ===\n",
      "Day 1: 0 / 3 correct\n",
      "Day 2: 1 / 3 correct\n",
      "Day 3: 0 / 3 correct\n",
      "Day 4: 0 / 3 correct\n",
      "Day 5: 0 / 3 correct\n",
      "Day 6: 2 / 3 correct\n",
      "Day 7: 0 / 3 correct\n",
      "Day 8: 0 / 3 correct\n",
      "Day 9: 0 / 3 correct\n",
      "Day 10: 0 / 3 correct\n",
      "Day 11: 1 / 3 correct\n",
      "Day 12: 0 / 3 correct\n",
      "Day 13: 0 / 3 correct\n",
      "Day 14: 1 / 3 correct\n",
      "Day 15: 1 / 3 correct\n",
      "Day 16: 0 / 3 correct\n",
      "Day 17: 0 / 3 correct\n",
      "Day 18: 0 / 3 correct\n",
      "Day 19: 1 / 3 correct\n",
      "Day 20: 1 / 3 correct\n",
      "Day 21: 0 / 3 correct\n",
      "Day 22: 0 / 3 correct\n",
      "Day 23: 0 / 3 correct\n",
      "Day 24: 1 / 3 correct\n",
      "Day 25: 1 / 3 correct\n",
      "Day 26: 0 / 3 correct\n",
      "Day 27: 0 / 3 correct\n",
      "Day 28: 1 / 3 correct\n",
      "Day 29: 0 / 3 correct\n",
      "Day 30: 0 / 3 correct\n",
      "Day 31: 0 / 3 correct\n",
      "Day 32: 1 / 3 correct\n",
      "Day 33: 0 / 3 correct\n",
      "Day 34: 0 / 3 correct\n",
      "Day 35: 0 / 3 correct\n",
      "Day 36: 0 / 3 correct\n",
      "Day 37: 0 / 3 correct\n",
      "Day 38: 1 / 3 correct\n",
      "Day 39: 0 / 3 correct\n",
      "Day 40: 0 / 3 correct\n",
      "Day 41: 1 / 3 correct\n",
      "Day 42: 1 / 3 correct\n",
      "Day 43: 0 / 3 correct\n",
      "Day 44: 1 / 3 correct\n",
      "Day 45: 1 / 3 correct\n",
      "Day 46: 1 / 3 correct\n",
      "Day 47: 0 / 3 correct\n",
      "Day 48: 1 / 3 correct\n",
      "Day 49: 0 / 3 correct\n",
      "Day 50: 1 / 3 correct\n",
      "Day 51: 0 / 3 correct\n",
      "Day 52: 1 / 3 correct\n",
      "Day 53: 1 / 3 correct\n",
      "Day 54: 0 / 3 correct\n",
      "Day 55: 1 / 3 correct\n",
      "Day 56: 1 / 3 correct\n",
      "Day 57: 0 / 3 correct\n",
      "Day 58: 0 / 3 correct\n",
      "Day 59: 0 / 3 correct\n",
      "Day 60: 0 / 3 correct\n",
      "Day 61: 2 / 3 correct\n",
      "Day 62: 1 / 3 correct\n",
      "Day 63: 1 / 3 correct\n",
      "Day 64: 0 / 3 correct\n",
      "Day 65: 0 / 3 correct\n",
      "Day 66: 0 / 3 correct\n",
      "Day 67: 1 / 3 correct\n",
      "Day 68: 3 / 3 correct\n",
      "Day 69: 1 / 3 correct\n",
      "Day 70: 1 / 3 correct\n",
      "Day 71: 0 / 3 correct\n",
      "Day 72: 0 / 3 correct\n",
      "Day 73: 1 / 3 correct\n",
      "Day 74: 1 / 3 correct\n",
      "Day 75: 0 / 3 correct\n",
      "Day 76: 1 / 3 correct\n",
      "Day 77: 0 / 3 correct\n",
      "Day 78: 0 / 3 correct\n",
      "Day 79: 0 / 3 correct\n",
      "Day 80: 0 / 3 correct\n",
      "Day 81: 1 / 3 correct\n",
      "Day 82: 1 / 3 correct\n",
      "Day 83: 1 / 3 correct\n",
      "Day 84: 0 / 3 correct\n",
      "Day 85: 1 / 3 correct\n",
      "Day 86: 0 / 3 correct\n",
      "Day 87: 0 / 3 correct\n",
      "Day 88: 1 / 3 correct\n",
      "Day 89: 0 / 3 correct\n",
      "Day 90: 0 / 3 correct\n",
      "Day 91: 0 / 3 correct\n",
      "Day 92: 0 / 3 correct\n",
      "Day 93: 0 / 3 correct\n",
      "Day 94: 0 / 3 correct\n",
      "Day 95: 0 / 3 correct\n",
      "Day 96: 0 / 3 correct\n",
      "Day 97: 0 / 3 correct\n",
      "Day 98: 1 / 3 correct\n",
      "Day 99: 0 / 3 correct\n",
      "Day 100: 0 / 3 correct\n",
      "\n",
      "Average Top‑3 Hit Rate Across 100 Days: 0.4300\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================\n",
    "# 1. TRAIN CATBOOST REGRESSOR ON LOG-SHARES\n",
    "# ============================================================\n",
    "\n",
    "reg_model = CatBoostRegressor(\n",
    "    iterations=500,\n",
    "    depth=6,\n",
    "    learning_rate=0.05,\n",
    "    loss_function=\"RMSE\",\n",
    "    verbose=False,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# y_train_reg_log = np.log1p(train_df['shares'])\n",
    "reg_model.fit(X_train, y_train_reg_log)\n",
    "\n",
    "# ============================================================\n",
    "# 2. PREDICT ON FULL TEST SET\n",
    "# ============================================================\n",
    "\n",
    "y_pred_log = reg_model.predict(X_test_full)\n",
    "y_pred_shares = np.expm1(y_pred_log)   # convert back to original scale\n",
    "\n",
    "# ============================================================\n",
    "# 3. CONVERT REGRESSION OUTPUT → CLASSIFICATION LABELS\n",
    "# ============================================================\n",
    "\n",
    "y_pred_class = (y_pred_shares >= high_thresh).astype(int)\n",
    "\n",
    "print(\"\\n=== CLASSIFICATION REPORT (REGRESSION MODEL) ===\")\n",
    "print(classification_report(y_test_full_class, y_pred_class, digits=3))\n",
    "\n",
    "print(\"\\n=== CONFUSION MATRIX ===\")\n",
    "print(confusion_matrix(y_test_full_class, y_pred_class))\n",
    "\n",
    "# For ROC-AUC we need probabilities → normalize predicted shares\n",
    "y_pred_proba = (y_pred_shares - y_pred_shares.min()) / (y_pred_shares.max() - y_pred_shares.min())\n",
    "\n",
    "auc = roc_auc_score(y_test_full_class, y_pred_proba)\n",
    "print(f\"\\nTest ROC-AUC (regression-based): {auc:.3f}\")\n",
    "\n",
    "# ============================================================\n",
    "# 4. DAILY TOP‑3 HIT EVALUATION (RANKING METRIC)\n",
    "# ============================================================\n",
    "\n",
    "daily_hits = []\n",
    "\n",
    "for X_day, y_day_class in zip(X_test_sets, y_test_sets_class):\n",
    "\n",
    "    if len(X_day) == 0:\n",
    "        daily_hits.append(0)\n",
    "        continue\n",
    "\n",
    "    # 1. Predict log-shares → shares\n",
    "    y_day_pred_log = reg_model.predict(X_day)\n",
    "    y_day_pred_shares = np.expm1(y_day_pred_log)\n",
    "\n",
    "    # Ranking dataframe\n",
    "    day_df = pd.DataFrame({\n",
    "        \"pred_shares\": y_day_pred_shares,\n",
    "        \"true_popular\": y_day_class.values\n",
    "    })\n",
    "\n",
    "    # 2. Top‑3 predicted by regression\n",
    "    top3_pred = day_df.sort_values(\"pred_shares\", ascending=False).head(3)\n",
    "\n",
    "    # 3. Top‑3 true popular\n",
    "    top3_true = day_df.sort_values(\"true_popular\", ascending=False).head(3)\n",
    "\n",
    "    pred_idx = set(top3_pred.index)\n",
    "    true_idx = set(top3_true.index)\n",
    "\n",
    "    # 4. Count hits\n",
    "    hits = len(pred_idx & true_idx)\n",
    "    daily_hits.append(hits)\n",
    "\n",
    "# 5. Summary\n",
    "average_hits = np.mean(daily_hits)\n",
    "\n",
    "print(\"\\n=== DAILY TOP‑3 HIT RESULTS (REGRESSION MODEL) ===\")\n",
    "for day, hits in enumerate(daily_hits, start=1):\n",
    "    print(f\"Day {day}: {hits} / 3 correct\")\n",
    "\n",
    "print(f\"\\nAverage Top‑3 Hit Rate Across 100 Days: {average_hits:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
