{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81dbcd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import visualise_gridsearch, fetch_top_predictions, make_top_3\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline as SkPipeline\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.combine import SMOTETomek\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import KFold, TimeSeriesSplit, GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82991883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution:\n",
      "shares\n",
      "0    35615\n",
      "1     4029\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/OnlineNewsPopularity.csv')\n",
    "df = df.rename(columns=lambda x: x.strip())\n",
    "y_raw = df['shares']\n",
    "\n",
    "POPULARITY_SPLIT = 0.9\n",
    "\n",
    "high_thresh = y_raw.quantile(POPULARITY_SPLIT)\n",
    "y_class = (y_raw >= high_thresh).astype(int)\n",
    "\n",
    "print(\"Class distribution:\")\n",
    "print(y_class.value_counts())\n",
    "\n",
    "df_sorted = df.copy().sort_values('timedelta', ascending=False)\n",
    "\n",
    "TRAIN_SPLIT = 0.85\n",
    "train_size = int(len(df_sorted) * TRAIN_SPLIT)\n",
    "\n",
    "train_df = df_sorted.iloc[:train_size]\n",
    "test_df = df_sorted.iloc[train_size:]\n",
    "\n",
    "X_train = train_df.drop(columns=['url', 'timedelta', 'shares'])\n",
    "y_train_class = (train_df['shares'] >= high_thresh).astype(int)\n",
    "y_train_reg_log = np.log1p(train_df['shares'])\n",
    "\n",
    "X_test_full = test_df.drop(columns=['url', 'timedelta', 'shares'])\n",
    "y_test_full_class = (test_df['shares'] >= high_thresh).astype(int)\n",
    "y_test_full_reg_log = np.log1p(test_df['shares'])\n",
    "\n",
    "test_splits = np.array_split(test_df, 100)\n",
    "\n",
    "X_test_sets = []\n",
    "y_test_sets_class = []\n",
    "y_test_sets_reg_log = []\n",
    "\n",
    "for ts in test_splits:\n",
    "    X_test_sets.append(ts.drop(columns=['url', 'timedelta', 'shares']))\n",
    "    y_test_sets_class.append((ts['shares'] >= high_thresh).astype(int))\n",
    "    y_test_sets_reg_log.append(np.log1p(ts['shares']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4124346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1e19f7d9590>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "model = CatBoostClassifier(\n",
    "    iterations=300,\n",
    "    depth=6,\n",
    "    learning_rate=0.1,\n",
    "    loss_function=\"Logloss\",\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "853938a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DAILY TOP‑3 HIT RESULTS ===\n",
      "Day 1: 0 / 3 correct\n",
      "Day 2: 1 / 3 correct\n",
      "Day 3: 1 / 3 correct\n",
      "Day 4: 0 / 3 correct\n",
      "Day 5: 0 / 3 correct\n",
      "Day 6: 2 / 3 correct\n",
      "Day 7: 0 / 3 correct\n",
      "Day 8: 0 / 3 correct\n",
      "Day 9: 0 / 3 correct\n",
      "Day 10: 0 / 3 correct\n",
      "Day 11: 1 / 3 correct\n",
      "Day 12: 0 / 3 correct\n",
      "Day 13: 0 / 3 correct\n",
      "Day 14: 1 / 3 correct\n",
      "Day 15: 0 / 3 correct\n",
      "Day 16: 0 / 3 correct\n",
      "Day 17: 0 / 3 correct\n",
      "Day 18: 0 / 3 correct\n",
      "Day 19: 0 / 3 correct\n",
      "Day 20: 1 / 3 correct\n",
      "Day 21: 1 / 3 correct\n",
      "Day 22: 0 / 3 correct\n",
      "Day 23: 0 / 3 correct\n",
      "Day 24: 1 / 3 correct\n",
      "Day 25: 0 / 3 correct\n",
      "Day 26: 0 / 3 correct\n",
      "Day 27: 0 / 3 correct\n",
      "Day 28: 0 / 3 correct\n",
      "Day 29: 0 / 3 correct\n",
      "Day 30: 1 / 3 correct\n",
      "Day 31: 1 / 3 correct\n",
      "Day 32: 0 / 3 correct\n",
      "Day 33: 1 / 3 correct\n",
      "Day 34: 0 / 3 correct\n",
      "Day 35: 0 / 3 correct\n",
      "Day 36: 0 / 3 correct\n",
      "Day 37: 0 / 3 correct\n",
      "Day 38: 1 / 3 correct\n",
      "Day 39: 0 / 3 correct\n",
      "Day 40: 0 / 3 correct\n",
      "Day 41: 0 / 3 correct\n",
      "Day 42: 1 / 3 correct\n",
      "Day 43: 1 / 3 correct\n",
      "Day 44: 1 / 3 correct\n",
      "Day 45: 1 / 3 correct\n",
      "Day 46: 1 / 3 correct\n",
      "Day 47: 0 / 3 correct\n",
      "Day 48: 0 / 3 correct\n",
      "Day 49: 0 / 3 correct\n",
      "Day 50: 0 / 3 correct\n",
      "Day 51: 0 / 3 correct\n",
      "Day 52: 0 / 3 correct\n",
      "Day 53: 1 / 3 correct\n",
      "Day 54: 1 / 3 correct\n",
      "Day 55: 2 / 3 correct\n",
      "Day 56: 0 / 3 correct\n",
      "Day 57: 0 / 3 correct\n",
      "Day 58: 0 / 3 correct\n",
      "Day 59: 0 / 3 correct\n",
      "Day 60: 1 / 3 correct\n",
      "Day 61: 1 / 3 correct\n",
      "Day 62: 1 / 3 correct\n",
      "Day 63: 1 / 3 correct\n",
      "Day 64: 0 / 3 correct\n",
      "Day 65: 0 / 3 correct\n",
      "Day 66: 1 / 3 correct\n",
      "Day 67: 0 / 3 correct\n",
      "Day 68: 3 / 3 correct\n",
      "Day 69: 0 / 3 correct\n",
      "Day 70: 0 / 3 correct\n",
      "Day 71: 0 / 3 correct\n",
      "Day 72: 1 / 3 correct\n",
      "Day 73: 0 / 3 correct\n",
      "Day 74: 1 / 3 correct\n",
      "Day 75: 0 / 3 correct\n",
      "Day 76: 2 / 3 correct\n",
      "Day 77: 0 / 3 correct\n",
      "Day 78: 0 / 3 correct\n",
      "Day 79: 1 / 3 correct\n",
      "Day 80: 1 / 3 correct\n",
      "Day 81: 1 / 3 correct\n",
      "Day 82: 0 / 3 correct\n",
      "Day 83: 2 / 3 correct\n",
      "Day 84: 1 / 3 correct\n",
      "Day 85: 1 / 3 correct\n",
      "Day 86: 0 / 3 correct\n",
      "Day 87: 1 / 3 correct\n",
      "Day 88: 2 / 3 correct\n",
      "Day 89: 0 / 3 correct\n",
      "Day 90: 0 / 3 correct\n",
      "Day 91: 1 / 3 correct\n",
      "Day 92: 0 / 3 correct\n",
      "Day 93: 0 / 3 correct\n",
      "Day 94: 0 / 3 correct\n",
      "Day 95: 0 / 3 correct\n",
      "Day 96: 0 / 3 correct\n",
      "Day 97: 0 / 3 correct\n",
      "Day 98: 1 / 3 correct\n",
      "Day 99: 1 / 3 correct\n",
      "Day 100: 0 / 3 correct\n",
      "\n",
      "Average Top‑3 Hit Rate Across 100 Days: 0.4700\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "daily_hits = []\n",
    "\n",
    "for X_day, y_day_class in zip(X_test_sets, y_test_sets_class):\n",
    "\n",
    "    # Skip empty days (safety)\n",
    "    if len(X_day) == 0:\n",
    "        daily_hits.append(0)\n",
    "        continue\n",
    "\n",
    "    # --- 1. Predict probabilities for that day ---\n",
    "    y_proba_day = model.predict_proba(X_day)[:, 1]\n",
    "\n",
    "    # Build dataframe for ranking\n",
    "    day_df = pd.DataFrame({\n",
    "        \"proba\": y_proba_day,\n",
    "        \"true_popular\": y_day_class.values\n",
    "    })\n",
    "\n",
    "    # --- 2. Top‑3 predicted popular articles ---\n",
    "    top3_pred = day_df.sort_values(\"proba\", ascending=False).head(3)\n",
    "\n",
    "    # --- 3. True top‑3 actual popular articles ---\n",
    "    # true_popular is already 0/1 based on top‑10% threshold\n",
    "    top3_true = day_df.sort_values(\"true_popular\", ascending=False).head(3)\n",
    "\n",
    "    pred_idx = set(top3_pred.index)\n",
    "    true_idx = set(top3_true.index)\n",
    "\n",
    "    # --- 4. Count hits ---\n",
    "    hits = len(pred_idx & true_idx)\n",
    "    daily_hits.append(hits)\n",
    "\n",
    "# --- 5. Average hit rate across all 100 days ---\n",
    "average_hits = np.mean(daily_hits)\n",
    "\n",
    "print(\"\\n=== DAILY TOP‑3 HIT RESULTS ===\")\n",
    "for day, hits in enumerate(daily_hits, start=1):\n",
    "    print(f\"Day {day}: {hits} / 3 correct\")\n",
    "\n",
    "print(f\"\\nAverage Top‑3 Hit Rate Across 100 Days: {average_hits:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
